# actual classification
sum(pred == data[,11]) / nrow(data)
# call ksvm. Vanilladot is a simple linear kernel.
model <- ksvm(data[,1:10],data[,11],type="C-svc",kernel="rbfdot",C=90000,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
# calculate a0
a0 <- -model@b
# see what the model predicts
pred <- predict(model,data[,1:10])
# see what fraction of the model’s predictions match the
# actual classification
sum(pred == data[,11]) / nrow(data)
# call ksvm. Vanilladot is a simple linear kernel.
model <- ksvm(data[,1:10],data[,11],type="C-svc",kernel="rbfdot",C=100000,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
# calculate a0
a0 <- -model@b
# see what the model predicts
pred <- predict(model,data[,1:10])
# see what fraction of the model’s predictions match the
# actual classification
sum(pred == data[,11]) / nrow(data)
# call ksvm. Vanilladot is a simple linear kernel.
model <- ksvm(data[,1:10],data[,11],type="C-svc",kernel="rbfdot",C=10000000,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
# calculate a0
a0 <- -model@b
# see what the model predicts
pred <- predict(model,data[,1:10])
# see what fraction of the model’s predictions match the
# actual classification
sum(pred == data[,11]) / nrow(data)
# call ksvm. Vanilladot is a simple linear kernel.
model <- ksvm(data[,1:10],data[,11],type="C-svc",kernel="rbfdot",C=1000000,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
# calculate a0
a0 <- -model@b
# see what the model predicts
pred <- predict(model,data[,1:10])
# see what fraction of the model’s predictions match the
# actual classification
sum(pred == data[,11]) / nrow(data)
# call ksvm. Vanilladot is a simple linear kernel.
model <- ksvm(data[,1:10],data[,11],type="C-svc",kernel="rbfdot",C=10000000,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
# calculate a0
a0 <- -model@b
# see what the model predicts
pred <- predict(model,data[,1:10])
# see what fraction of the model’s predictions match the
# actual classification
sum(pred == data[,11]) / nrow(data)
sample(1:nrow(data))
sample(1:nrow(data),.8*nrow(data) ,replace = TRUE)
.8*nrow(data)
nrow(data)
sample(1:nrow(data),floor(.8*nrow(data)) ,replace = TRUE)
test <- data[-train_ind,]
train_ind <-sample(1:nrow(data),floor(.8*nrow(data)) ,replace = TRUE)
set.seed(0)
train <- data[train_ind,]
test <- data[-train_ind,]
train_ind <-sample(1:nrow(data),floor(.8*nrow(data)) ,replace = TRUE)
set.seed(0)
train_ind <-sample(1:nrow(data),floor(.8*nrow(data)) ,replace = TRUE)
train <- data[train_ind,]
test <- data[-train_ind,]
train
test
nrow(test)
nrow(train)
set.seed(0)
train_ind <-sample(1:nrow(data),floor(.8*nrow(data)) ,replace = TRUE)
train <- data[train_ind,]
test <- data[-train_ind,]
currentAccuracy <- 0
bestAccuracy <- 0
bestC <- 0
for (c in 1:100000){
model <- ksvm(train[,1:10],train[,11],type="C-svc",kernel="rbfdot",C=c,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
# calculate a0
a0 <- -model@b
# see what the model predicts
pred <- predict(model,test[,1:10])
# see what fraction of the model’s predictions match the
# actual classification
currentAccuracy <- sum(pred == test[,11]) / nrow(test)
if( currentAccuracy > bestAccuracy){
bestAccuracy <- currentAccuracy
bestC <- c
}
}
c
bestC
bestAccuracy
set.seed(0)
train_ind <-sample(1:nrow(data),floor(.8*nrow(data)) ,replace = TRUE)
train <- data[train_ind,]
test <- data[-train_ind,]
currentAccuracy <- 0
bestAccuracy <- 0
bestC <- 0
for (c in 1:100000){
model <- ksvm(train[,1:10],train[,11],type="C-svc",kernel="rbfdot",C=c,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
# calculate a0
a0 <- -model@b
# see what the model predicts
pred <- predict(model,test[,1:10])
# see what fraction of the model’s predictions match the
# actual classification
currentAccuracy <- sum(pred == test[,11]) / nrow(test)
if( currentAccuracy > bestAccuracy){
bestAccuracy <- currentAccuracy
bestC <- c
}
flush.console()
print(c/1000000)
}
set.seed(0)
train_ind <-sample(1:nrow(data),floor(.8*nrow(data)) ,replace = TRUE)
train <- data[train_ind,]
test <- data[-train_ind,]
currentAccuracy <- 0
bestAccuracy <- 0
bestC <- 0
for (c in 1:100000){
model <- ksvm(train[,1:10],train[,11],type="C-svc",kernel="rbfdot",C=c,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
# calculate a0
a0 <- -model@b
# see what the model predicts
pred <- predict(model,test[,1:10])
# see what fraction of the model’s predictions match the
# actual classification
currentAccuracy <- sum(pred == test[,11]) / nrow(test)
if( currentAccuracy > bestAccuracy){
bestAccuracy <- currentAccuracy
bestC <- c
}
print(c/1000000)
flush.console()
}
for (c in 1:100){
model <- ksvm(train[,1:10],train[,11],type="C-svc",kernel="rbfdot",C=c,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
# calculate a0
a0 <- -model@b
# see what the model predicts
pred <- predict(model,test[,1:10])
# see what fraction of the model’s predictions match the
# actual classification
currentAccuracy <- sum(pred == test[,11]) / nrow(test)
if( currentAccuracy > bestAccuracy){
bestAccuracy <- currentAccuracy
bestC <- c
}
#print(c/1000000)
#flush.console()
}
set.seed(0)
train_ind <-sample(1:nrow(data),floor(.8*nrow(data)) ,replace = TRUE)
train <- data[train_ind,]
test <- data[-train_ind,]
currentAccuracy <- 0
bestAccuracy <- 0
bestC <- 0
for (c in 1:100){
model <- ksvm(train[,1:10],train[,11],type="C-svc",kernel="rbfdot",C=c,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
# calculate a0
a0 <- -model@b
# see what the model predicts
pred <- predict(model,test[,1:10])
# see what fraction of the model’s predictions match the
# actual classification
currentAccuracy <- sum(pred == test[,11]) / nrow(test)
if( currentAccuracy > bestAccuracy){
bestAccuracy <- currentAccuracy
bestC <- c
}
#print(c/1000000)
#flush.console()
}
c
bestC
model
10^8
seq(1,10^8,100)
seq(1,10^8,500)
seq(1,10^8,1000)
len(seq(1,10^8,1000))
length(seq(1,10^8,1000))
model <- ksvm(train[,1:10],train[,11],type="C-svc",kernel="rbfdot",C=c,scaled=TRUE)
set.seed(0)
train_ind <-sample(1:nrow(data),floor(.8*nrow(data)) ,replace = TRUE)
train <- data[train_ind,]
test <- data[-train_ind,]
currentAccuracy <- 0
bestAccuracy <- 0
bestC <- 0
for (c in seq(1,10^8,1000)){
model <- ksvm(train[,1:10],train[,11],type="C-svc",kernel="rbfdot",C=c,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
# calculate a0
a0 <- -model@b
# see what the model predicts
pred <- predict(model,test[,1:10])
# see what fraction of the model’s predictions match the
# actual classification
currentAccuracy <- sum(pred == test[,11]) / nrow(test)
if( currentAccuracy > bestAccuracy){
bestAccuracy <- currentAccuracy
bestC <- c
}
#print(c/1000000)
#flush.console()
}
set.seed(0)
train_ind <-sample(1:nrow(data),floor(.8*nrow(data)) ,replace = TRUE)
train <- data[train_ind,]
test <- data[-train_ind,]
currentAccuracy <- 0
bestAccuracy <- 0
bestC <- 0
for (c in seq(1,10^8,10000)){
model <- ksvm(train[,1:10],train[,11],type="C-svc",kernel="rbfdot",C=c,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
# calculate a0
a0 <- -model@b
# see what the model predicts
pred <- predict(model,test[,1:10])
# see what fraction of the model’s predictions match the
# actual classification
currentAccuracy <- sum(pred == test[,11]) / nrow(test)
if( currentAccuracy > bestAccuracy){
bestAccuracy <- currentAccuracy
bestC <- c
}
#print(c/1000000)
#flush.console()
}
length(seq(1,10^8,10000))
c
length(seq(1,10^8,10000))
set.seed(0)
train_ind <-sample(1:nrow(data),floor(.8*nrow(data)) ,replace = TRUE)
train <- data[train_ind,]
test <- data[-train_ind,]
currentAccuracy <- 0
bestAccuracy <- 0
bestC <- 0
for (c in seq(1,10^8,10000)){
model <- ksvm(train[,1:10],train[,11],type="C-svc",kernel="rbfdot",C=c,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
# calculate a0
a0 <- -model@b
# see what the model predicts
pred <- predict(model,test[,1:10])
# see what fraction of the model’s predictions match the
# actual classification
currentAccuracy <- sum(pred == test[,11]) / nrow(test)
if( currentAccuracy > bestAccuracy){
bestAccuracy <- currentAccuracy
bestC <- c
}
#print(c/1000000)
#flush.console()
}
c
bestAccuracy
bestC
length(seq(1,10^8,100000))
set.seed(0)
train_ind <-sample(1:nrow(data),floor(.8*nrow(data)) ,replace = TRUE)
train <- data[train_ind,]
test <- data[-train_ind,]
currentAccuracy <- 0
bestAccuracy <- 0
bestC <- 0
for (c in seq(1,10^8,100000)){
model <- ksvm(train[,1:10],train[,11],type="C-svc",kernel="rbfdot",C=c,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
# calculate a0
a0 <- -model@b
# see what the model predicts
pred <- predict(model,test[,1:10])
# see what fraction of the model’s predictions match the
# actual classification
currentAccuracy <- sum(pred == test[,11]) / nrow(test)
if( currentAccuracy > bestAccuracy){
bestAccuracy <- currentAccuracy
bestC <- c
}
#print(c/1000000)
#flush.console()
}
c
c
c
bestAccuracy
bestC
length(seq(0,1,.01))
c
bestAccuracy
bestC
set.seed(0)
train_ind <-sample(1:nrow(data),floor(.8*nrow(data)) ,replace = TRUE)
train <- data[train_ind,]
test <- data[-train_ind,]
currentAccuracy <- 0
bestAccuracy <- 0
bestC <- 0
for (c in seq(0,1,.01)){
model <- ksvm(train[,1:10],train[,11],type="C-svc",kernel="rbfdot",C=c,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
# calculate a0
a0 <- -model@b
# see what the model predicts
pred <- predict(model,test[,1:10])
# see what fraction of the model’s predictions match the
# actual classification
currentAccuracy <- sum(pred == test[,11]) / nrow(test)
if( currentAccuracy > bestAccuracy){
bestAccuracy <- currentAccuracy
bestC <- c
bestModel <- model
}
#print(c/1000000)
#flush.console()
}
set.seed(0)
train_ind <-sample(1:nrow(data),floor(.8*nrow(data)) ,replace = TRUE)
train <- data[train_ind,]
test <- data[-train_ind,]
currentAccuracy <- 0
bestAccuracy <- 0
bestC <- 0
for (c in seq(0.01,1,.01)){
model <- ksvm(train[,1:10],train[,11],type="C-svc",kernel="rbfdot",C=c,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
# calculate a0
a0 <- -model@b
# see what the model predicts
pred <- predict(model,test[,1:10])
# see what fraction of the model’s predictions match the
# actual classification
currentAccuracy <- sum(pred == test[,11]) / nrow(test)
if( currentAccuracy > bestAccuracy){
bestAccuracy <- currentAccuracy
bestC <- c
bestModel <- model
}
#print(c/1000000)
#flush.console()
}
c
bestAccuracy
bestC
c
bestAccuracy
bestC
set.seed(0)
train_ind <-sample(1:nrow(data),floor(.8*nrow(data)) ,replace = TRUE)
train <- data[train_ind,]
test <- data[-train_ind,]
currentAccuracy <- 0
bestAccuracy <- 0
bestC <- 0
for (c in seq(0.01,1,.001)){
model <- ksvm(train[,1:10],train[,11],type="C-svc",kernel="rbfdot",C=c,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
# calculate a0
a0 <- -model@b
# see what the model predicts
pred <- predict(model,test[,1:10])
# see what fraction of the model’s predictions match the
# actual classification
currentAccuracy <- sum(pred == test[,11]) / nrow(test)
if( currentAccuracy > bestAccuracy){
bestAccuracy <- currentAccuracy
bestC <- c
bestModel <- model
}
#print(c/1000000)
#flush.console()
}
length(seq(0,1,.01))
c
bestAccuracy
bestAccuracy
c
bestAccuracy
bestC
set.seed(0)
train_ind <-sample(1:nrow(data),floor(.8*nrow(data)) ,replace = TRUE)
train <- data[train_ind,]
test <- data[-train_ind,]
currentAccuracy <- 0
bestAccuracy <- 0
bestC <- 0
for (c in seq(0.01,1,.0001)){
model <- ksvm(train[,1:10],train[,11],type="C-svc",kernel="rbfdot",C=c,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
# calculate a0
a0 <- -model@b
# see what the model predicts
pred <- predict(model,test[,1:10])
# see what fraction of the model’s predictions match the
# actual classification
currentAccuracy <- sum(pred == test[,11]) / nrow(test)
if( currentAccuracy > bestAccuracy){
bestAccuracy <- currentAccuracy
bestC <- c
bestModel <- model
}
#print(c/1000000)
#flush.console()
}
bestC
bestModel
model
bestModel
bestAccuracy
colSums(bestModel@xmatrix[[1]] * model@coef[[1]])
colSums(bestModel@xmatrix[[1]] * bestModel@coef[[1]])
a
colSums(bestModel@xmatrix[[1]] * bestModel@coef[[1]])
besta0 <-bestModel@b
besta <- colSums(bestModel@xmatrix[[1]] * bestModel@coef[[1]])
besta0
besta
a0
besta0
besta
set.seed(0)
train_ind <-sample(1:nrow(data),floor(.8*nrow(data)) ,replace = TRUE)
train <- data[train_ind,]
test <- data[-train_ind,]
currentAccuracy <- 0
bestAccuracy <- 0
bestC <- 0
for (c in seq(0.06,1,.0001)){
model <- ksvm(train[,1:10],train[,11],type="C-svc",kernel="rbfdot",C=c,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
# calculate a0
a0 <- -model@b
# see what the model predicts
pred <- predict(model,test[,1:10])
# see what fraction of the model’s predictions match the
# actual classification
currentAccuracy <- sum(pred == test[,11]) / nrow(test)
if( currentAccuracy > bestAccuracy){
bestAccuracy <- currentAccuracy
bestC <- c
bestModel <- model
}
#print(c/1000000)
#flush.console()
}
set.seed(0)
train_ind <-sample(1:nrow(data),floor(.8*nrow(data)) ,replace = TRUE)
train <- data[train_ind,]
test <- data[-train_ind,]
currentAccuracy <- 0
bestAccuracy <- 0
bestC <- 0
for (c in seq(0.065,0.065,.0001)){
model <- ksvm(train[,1:10],train[,11],type="C-svc",kernel="rbfdot",C=c,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
# calculate a0
a0 <- -model@b
# see what the model predicts
pred <- predict(model,test[,1:10])
# see what fraction of the model’s predictions match the
# actual classification
currentAccuracy <- sum(pred == test[,11]) / nrow(test)
if( currentAccuracy > bestAccuracy){
bestAccuracy <- currentAccuracy
bestC <- c
bestModel <- model
}
#print(c/1000000)
#flush.console()
}
kknn
library(kknn)
install.packages('kknn')
library(kknn)
?kknn
kknn(V1~.,train,test)
